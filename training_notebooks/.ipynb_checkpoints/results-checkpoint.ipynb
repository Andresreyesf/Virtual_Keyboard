{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)\n",
    "dec_prec = 3\n",
    "plt.rcParams['figure.figsize'] = [12.0, 4.0]\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = ['train_1_orig.npy', 'train_1_2drop.npy', 'train_1_dropout_0.50.npy', 'train_1_2dense.npy', 'train_1_dropout_0.50_2dense.npy', \n",
    "              'train_1_orig_nw.npy', 'train_1_dropout_0.50_nw.npy', 'train_1_2dense_nw.npy', 'train_1_dropout_0.50_2dense_nw.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_curves = []\n",
    "for test_name in test_names:\n",
    "    test_curves.append( np.load(f'curves/{test_name}', allow_pickle=True).item() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(columns=['name', 'model', 'AUC', 'precision', 'recall', 'acc_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_curve in test_curves:\n",
    "    test_curve['auc'] = np.round(test_curve['auc'],dec_prec)\n",
    "    test_curve['precision'] = np.round(test_curve['precision'],dec_prec)\n",
    "    test_curve['recall'] = np.round(test_curve['recall'],dec_prec)\n",
    "    test_curve['acc_val_last'] = np.round(test_curve['acc_val'][-1],dec_prec)\n",
    "    new_row = {\n",
    "        'name':test_curve['name'], \n",
    "        'model':test_curve['model'],\n",
    "        'AUC':test_curve['auc'],\n",
    "        'precision':test_curve['precision'],\n",
    "        'recall':test_curve['recall'],\n",
    "        'acc_val':test_curve['acc_val_last']\n",
    "    }\n",
    "    table = table.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_curve in test_curves:\n",
    "    print(f'NAME: {test_curve[\"name\"]}, MODEL: {test_curve[\"model\"]}')\n",
    "    print(f'AUC: {test_curve[\"auc\"]}, precision: {test_curve[\"precision\"]}, recall: {test_curve[\"recall\"]}, acc_val: {test_curve[\"acc_val_last\"]}')\n",
    "    loss_p = test_curve['loss_train']\n",
    "    valoss_p = test_curve['loss_val']\n",
    "    acc_p = test_curve['acc_train']\n",
    "    valacc_p = test_curve['acc_val']\n",
    "    epochs = range(5, len(loss_p) + 5) \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_p, 'g', label='Training loss')\n",
    "    plt.plot(epochs, valoss_p, 'y', label='Validation loss')\n",
    "    plt.title(f'Training Curve: Training and Validation Loss.')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim([0,1.5])\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc_p, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, valacc_p, 'y', label='Validation accuracy')\n",
    "    plt.title(f'Training Curve: Training and Validation Accuracy.')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim([0,1.0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_curves[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_p = test_curve['loss_train']\n",
    "valoss_p = test_curve['loss_val']\n",
    "acc_p = test_curve['acc_train']\n",
    "valacc_p = test_curve['acc_val']\n",
    "epochs = range(5, len(loss_p) + 5) \n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss_p, 'g', label='Training loss')\n",
    "plt.plot(epochs, valoss_p, 'y', label='Validation loss')\n",
    "plt.title(f'Training Curve: Training and Validation Loss.')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0,1.5])\n",
    "plt.savefig('figures/train_loss.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc_p, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, valacc_p, 'y', label='Validation accuracy')\n",
    "    plt.title(f'Training Curve: Training and Validation Accuracy.')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim([0.4,1.0])\n",
    "    plt.savefig('figures/train_acc.eps', format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
